<!DOCTYPE html>
<html>
    <head>
        <meta content="width=device-width, initial-scale=1.0" name="viewport">
        <meta content="Heman Gandhi" name="author">
        <meta content= "I'm Heman Gandhi, a junior pursuing his math and CS degree." name="description">
        <meta content=
        "Heman Gandhi, Interactive Resume, programmer, Web developer, Full Stack Developer, Interactive CV, Resume, CV, Algorithms, Programming, Learning, mathematics, category theory" name="keywords">
        <title>Systems Programming I wish I Learned</title>
        <link rel="stylesheet" href="../css/styles.css"/>
        <link rel="stylesheet" href="../css/code.css"/>
    </head>

    <body>
        <div class="centered-div">
            <div class="left-bit">Learning to Listen to Cpp Con Talks</div>
            <div class="right-bit">
                <a href="../index.html">/home</a>
                <a href="../experience.html">/experience</a>
                <a href="../projects.html">/projects</a>
                <a href="../skills.html">/skills</a>
                <a href="../etc.html">/etc</a>
                <div class="cv-link">/cv
                    <ul>
                        <li><a href="heman.cv.pdf">/software engineering cv</a></li>
                        <li><a href="heman.research.cv.pdf">/research cv</a></li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="content-blog centered-div center-text">
	  <label for="slide-nr">Choose a slide:</label>
	  <select id="slide-nr">
	  </select>
        </div>

        <div class="content-blog centered-div center-text">
	  <div id="slide-0">
            <div class="big-title">What is this?</div>
            <div class="padded-text">
	      A blog that's a slideshow so that I can present my thoughts in this form.
            </div>
            <div class="padded-text">
	      Click the buttons below to see the slides. Or use the drop-down above.
            </div>
            <div class="padded-text">
	      I can't be bothered to CSS well enough to keep those button in the same spot.
            </div>
            <div class="padded-text">
	      Also, some parts have no reason to be one slide, except that I was lazy. This might be better thought of as a collection of mini-posts around a sort of trend I'm seeing.
            </div>
	  </div>

	  <div id="slide-1">
            <div class="big-title">Alternate Titles</div>
            <div class="padded-text">
	      Things to Think About When Watching CppCon
            </div>
            <div class="padded-text">
	      What I Wish I Knew About Low Level Langauges
            </div>
            <div class="padded-text">
	      How to Stop Worrying And Love Systems Programming
            </div>
            <div class="padded-text">
	      Trends in Programming Languages and Talks I Like
            </div>
	  </div>

	  <div id="slide-2">
            <div class="big-title">Actual Topics</div>
            <div class="padded-text place-title">
	      This is what I mean to include:
	      <ol>
		<li>The End of Moore's Law</li>
		<li>SIMD</li>
		<li>Async</li>
		<li>Atomics</li>
		<li>Instruction Execution</li>
		<li>Better Hash Map Implementations</li>
		<li>Benchmarking</li>
		<li>Static Checking and Correctness</li>
		<li>Superior C Syntax</li>
		<li>Modules</li>
		<li>Compile-Time Programming</li>
		<li>RAII</li>
		<li>Linear Types</li>
		<li>Error Handling</li>
		<li>Dispatch</li>
		<li>Type Erasure</li>
		<li>Things I Wish I Could Talk About</li>
	      </ol>
            </div>
            <div class="padded-text">
	      I should mention: I sort of prattle on about topics in whatever depth I feel like. If you can read (x86) assembler, know somethings about object-oriented programming, and have messed around with C, I think you should be able to follow most of what I ramble on about. If you are ever confused, please note that it's more likely my lack of coherence, patience, clarity, or editing, than it is any fault on your part.
            </div>
	  </div>

	  <div id="slide-3">
            <div class="big-title">The End of Moore's Law</div>
            <div class="padded-text place-title">
	      Moore's law was a rule of thumb that declared that CPUs would have double the number of transistors every year.
            </div>
            <div class="padded-text place-title">
	      This reached a physical limit. In particular, CPUs don't double in density any more. We've reached the peak clock rate for the time being.
            </div>
            <div class="padded-text place-title">
	      There are a few countermeasures: parallelism and alternate hardware. This is opening up the world of low-level programming where we can question how we're designing the interactions between the hardware and the programming language. We can look back again and ask: what are we doing? Are we doing the best we can? This leads to the next two big movements I'd like to talk about: SIMD and Async programming. It's worth noting that instruction execution is another important factor.
            </div>
            <div class="padded-text place-title">
	      There are two other noteworthy innovations are parts of SIMD:
	      <ul>
		<li>GPUs: great for SIMD, but really hard to use well for some tasks.</li>
		<li>TPUs: GPUs specialized even further for ML. I do not know enough about these to discuss them.</li>
	      </ul>
            </div>
	  </div>

	  <div id="slide-4">
            <div class="big-title">SIMD</div>
            <div class="padded-text place-title">
	      This is a parallelism paradigm that executes a single instruction on multiple datapoints in parallel.
            </div>
            <div class="padded-text place-title">
	      This is what GPUs do and they're really good at it, but the more interesting movement is the fact that CPUs also execute SIMD instructions and many compilers will output them.
            </div>
            <div class="padded-text place-title">
	      CPU SIMD is a strange sort of thing since it can only do some arithmetic operations on up to 128-bit values. Yet this can be faster for large enough lists. Look into AVX and AMX for industry implementations of this.
            </div>
	  </div>

	  <div id="slide-5">
            <div class="big-title">SIMD Algorithms</div>
            <div class="padded-text place-title">
	      This is more applicable to GPUs but brings up a lot of interesting points in SIMD programming.
            </div>
            <div class="padded-text place-title">
	      Fundamentally, there is an interesting quirk, best expressed in PTX (the GPU assembly language).
            </div>
	    <pre>
<span class="keyword">.reg .pred</span> p; <span class="comment">// declare p a predicate register.</span>
<span class="keyword">setp.lt.s32</span> p, i, n; <span class="comment">// p = (i < n)</span>
@p <span class="keyword">add.s32</span> i, i, 1; <span class="comment">// i++</span>
	    </pre>
            <div class="padded-text place-title">
	      Suppose <code>p</code> was not set, that <code>i >= n</code>. In this case, if all the GPU cores were running the same instruction in lock-step, what would happen?
            </div>
            <div class="padded-text place-title">
              Therein lies the catch: SIMD does not to branch very well. In GPUs, this branch would lead to some threads running a no-op. If there was an else case:
            </div>
	    <pre>
<span class="keyword">.reg .pred</span> p; <span class="comment">// declare p a predicate register.</span>
<span class="keyword">setp.lt.s32</span> p, i, n; <span class="comment">// p = (i < n)</span>
@p <span class="keyword">add.s32</span> i, i, 1; <span class="comment">// if (p) i++</span>
@!p <span class="keyword">add.s32</span> n, n, 1; <span class="comment">// if (!p) n++</span>
	    </pre>
            <div class="padded-text place-title">
	      Now, some threads will no-op in the first branch, and the rest will no-op in the second. This can be slow. It really depends.
            </div>
            <div class="padded-text place-title">
	      This changes the way some algorithms can be approached. There are a lot of good algorithms for SIMD, particularly at the level of parallelization that a GPU can offer. Parallel reductions (summing) and Bitonic sort are classics, but radix sort also exists.  Graph algorithms on GPUs are even more challenging as questions about the memory layout are esssential.
            </div>
	  </div>

	  <div id="slide-6">
            <div class="big-title">Async</div>
            <div class="padded-text place-title">
	      Another, simpler, more CPU-bound way to handle the fact that speed no longer doubles for free is the use of multi-threading. And one really interesting abstraction for it is asynchronous execution. Technically, the two are actually completely unrelated: we <i>could</i> run code in any wacky order (I see you Haskell) without running multiple threads, and we <i>could</i> make the execution order seem "synchronous" (or sort of linear) even if it crosses through multiple threads. However, marrying the two concepts justifies asyncronous execution while simplifying multithreading.
            </div>
            <div class="padded-text place-title">
	      <!-- &rsquo to not mess up emacs' syntax highlighting ((T_T) emawcs chan y) -->
	      This is also the culmination of a long movement that actually may have started in JavaScript. JavaScript used asynchrony for web development (which is how a lot of low-level usage is done too). In JavaScript, you&rsquo;d use async to load external resources so that the page could load and then wait for external requests. This was a slow and steady escalation (of which I&rsquo;ve only used the first half, and half-heartedly heard and read on the second): there was AJAX, then jQuery and promises, then Axios and Fetch, which finally reached compatibility with a native async/await syntax. This too may be best first seen in code:
            </div>
	    <pre>
<span class="keyword">async function</span> loadStuff() {
    <span class="keyword">let</span> someFirstThing = <span class="keyword">await</span> loadThatFirstThing();
}
	    </pre>
            <div class="padded-text place-title">
	      If you&rsquo;re familiar with promises, you&rsquo;d expect that they may fail. In this case there are two possible resolutions, <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/await">detailed here</a>.
            </div>
            <div class="padded-text place-title">
	      In either case, the notable thing is that this fits really well with &quot;left-leaning&quot; code. This is means that code does not end up in some nested callback mess. You can see this with the use of the <code>await</code> statement since it keeps the callback on the left instead of inside a scope and (hopefully) indentation level. However, there is an interesting complication that I do not know how JS addresses:
            </div>
	    <pre>
<span class="keyword">async fn</span> loadStuff() {
    <span class="keyword">let</span> someFirstThing = <span class="keyword">await</span> loadThatFirstThing();
    <span class="keyword">let</span> someOtherThing = <span class="keyword">await</span> loadThatOtherThing();
}
	    </pre>
            <div class="padded-text place-title">
	      Here, in Rust (note my cheeky <code>s/function/fn/g</code>), the <code>await</code>s will execute one after another. There are ways to <a href="https://docs.rs/futures/0.3.5/futures/macro.join.html">join</a> them so they will execute concurrently.
            </div>
            <div class="padded-text place-title">
	      This paradigm has some interesting implications that are related to ideas in RAII and with closures.
            </div>
	  </div>

	  <div id="slide-7">
            <div class="big-title">Atomics</div>
            <div class="padded-text">
	      <i>Somehow I cannot help but think of Dune when I say Atomics.</i>
            </div>
            <div class="padded-text place-title">
	      In a way the Dune reference might be relevant: you could want to nuke your code with atomics. Use these as carefully as most people would use Dune atomics. Or, like most people in Dune, don&rsquo;t.
            </div>
            <div class="padded-text place-title">
	      Atomics are instructions that cannot be divided. This is useful for one big reason: multithreading.
            </div>
	    <pre>
<span class="keyword">#include <span class="built-in">&lt;atomic&gt;</span></span>

<span class="keyword">template</span>&lt;<span class="keyword">class</span> T&gt;
<span class="keyword">class</span> Locked{
<span class="keyword">public</span>:
    Locked(T t): locked_(t), mutex_(<span class="keyword">false</span>) {}
    T& ExclusivelyAccess() {
        <span class="keyword">bool</span> f = <span class="keyword">false</span>;
        <span class="keyword">while</span>(!mutex_.compare_exchange_strong(f, <span class="keyword">true</span>));
        <span class="keyword">return</span> locked_;
    }
    <span class="keyword">void</span> EndExclusiveAccess() {
        mutex_ = <span class="keyword">false</span>;	
    }
    <span class="keyword">bool</span> IsHeld() { <span class="keyword">return</span> !mutex_; }
<span class="keyword">private</span>:
    <span class="built-in">std::atomic</span>&lt;<span class="keyword">bool</span>&gt; mutex_;
    T locked_;
};
	    </pre>
            <div class="padded-text place-title">
	      This a way to implement a lock. In theory. I have yet to test this (and I doubt I ever really will -- testing multithreading is really hard). A <code><span class="built-in">std::atomic</span>&lt;<span class="keyword">bool</span>&gt;</code> handles the locking, ensuring that between the check for whether the <code><span class="keyword">bool</span></code> was <code><span class="keyword">false</span></code> and when it was set to <code><span class="keyword">true</span></code>. This makes the locking safe. <a href="https://en.cppreference.com/w/cpp/atomic/atomic">Documentation on <code><span class="built-in">std::atomic</span></code>.</a> Be very careful with this: the built-in is great for small types that fit in hardware-based instructions. Otherwise you will see that the class will use locks and, honestly, it should.
            </div>
            <div class="padded-text place-title">
	      These are important basic building blocks. I will (theoretically) implement an improvement on this in <a href="#slide-15">my discussion on RAII.</a>
            </div>
	  </div>

	  <div id="slide-8">
            <div class="big-title">Execution Order</div>
            <div class="padded-text place-title">
	      (I only know how Intel does it (sorta) but the point here is that there can be a lot more abstraction than you&rsquo;re expecting.)
            </div>
            <div class="padded-text place-title">
	      This has to do with pipelining which is an essential point in modern computing. Memory is slow. This is really worth its own slide. Or emphasis.
            </div>
            <div class="big-title">Memory is Slow</div>
            <div class="padded-text place-title">
	      The CPU is about 100x faster so there are two key solutions:
	      <ul>
		<li>Caching</li>
		<li>Pipelining</li>
	      </ul>
	      I&rsquo;ll rant about caching later on. So this bit is about pipelining.
            </div>
            <div class="padded-text place-title">
	      Pipelining is where the CPU loads the next instruction while executing the current one. This has a lot of interesting issues, particularly with branching where there&rsquo;s a whole branch prediction system as I will discuss a bit later. But first: out of order execution. This is the fact that CPUs are really smart. Not just in as much as they compute, but also that they make sure they&rsquo;re getting fed instructions at all times. They pipeline, but they do one more thing: out of order execution.
            </div>
            <div class="padded-text place-title">
	      But let me get to the main point as I discuss these things.
            </div>
            <div class="place-title big-title">Meltdown: Attacking Out of Order Execution</div>
            <div class="padded-text place-title">
	      This is much better covered in the <a href="https://meltdownattack.com/meltdown.pdf" title="so the sumary below is for my ego">paper about this attack</a>.
            </div>
            <div class="padded-text place-title">
	      So first, let me describe instructions. x86, a comon commodity assembler, is a CISC assembly. This means that instructions can decompose into multiple different ones sometimes. Consider something like <code><span class="keyword">char</span> aznable = white_base[amuro][ray]</code> (suppose that <code>amuro</code> and <code>ray</code> were <code><span class="keyword">int</span></code>s and <code>white_base</code> is a <code><span class="keyword">char</span>[][]</code>).
            </div>
            <pre>
<span class="comment">;suppose %rdi is the address of white_base[0][0], %rbx = amuro, and %rcx = ray</span>
<span class="keyword">movq</span> %rdx, (%rdi, %rbx, 8)
<span class="keyword">mov</span> %al, (%rdx, %rcx)
<span class="comment">;now aznable is in %al</span>
            </pre>
            <div class="padded-text place-title">
	      Technically that assembly is more for illustrative purposes than it is for real technical stuff. This pair of instructions would expand into a few RISC instructions (RISC being the simpler assemblers whose instructions really are one instruction):
            </div>
            <pre>
<span class="comment">;suppose %rdi is the address of white_base[0][0], %rbx = amuro, and %rcx = ray</span>
<span class="keyword">mult</span> %rbx, %rbx, 8
<span class="keyword">add</span> %rdi, %rdi, %rbx
<span class="keyword">load</span> %rdx, %rdi
<span class="keyword">add</span> %rdx, %rcx
<span class="keyword">load</span> %al, %rdx
<span class="comment">;now aznable is in %al</span>
            </pre>
            <div class="padded-text place-title">
	      The <code><span class="keyword">mult</span></code> and <code><span class="keyword">add</span></code>s are in the x86 too, just hidden in the <a href="https://paul.bone.id.au/blog/2018/09/05/x86-addressing/">addressing modes</a>. The upshot (other than an assembly crash course that went faster than the red comet) is that CISC has to get turned into RISC (sort of -- it is probably more complicated and with different restrictions since the CPU does it).
            </div>
            <div class="padded-text place-title">
	      Since the CPU does it, it can also be smarter about its own state, and reorder instructions. In particular, consider the following C:
            </div>
            <pre>
<span class="keyword">#define</span> CACHE_LINE_SIZE 1024
<span class="keyword">char</span> probe[CACHE_LINE_SIZE * 256];	      
<span class="keyword">char</span> should_not_be_accessed = *pointer_into_kernel_memory;
<span class="keyword">char</span>* for_cache = &probe[should_not_be_accessed * CACHE_LINE_SIZE];
            </pre>
            <div class="padded-text place-title">
	      Here, the CPU actually will probably schedule the multiplication and read that happens <i>after</i> the pointer read to run <i>at the same time</i>. This is sort of magical since it really speeds up the the rate at which the CPU can execute instructions: it will hardly wait for the memory since it is perparing the subsequent operations.
            </div>
            <div class="padded-text place-title">
	      However, the example above is more interesting. If <code>pointer_into_kernel_memory</code> is actually a pointer to an address the running process cannot read, this will signal an error (<code>SIGSEGV</code> for instance). If the program can recover from that, however, the Meltdown vulnerability found that the <code>for_cache</code> pointer may have already been loaded and then unloaded once the exeception occured. This is not really an issue except that the cache will have changed (yes I will talk about caching). By reading what part of memory was loaded into the cache, the attacker can deduce the value of <code>should_not_be_accessed</code>.
            </div>
            <div class="place-title big-title">Spectre: Attacking Branch Prediction</div>
            <div class="padded-text place-title">
	      This too is better explained in <a href="https://spectreattack.com/spectre.pdf">the paper</a>.
            </div>
            <div class="padded-text place-title">
	      This is another example of speculative execution. Earlier, I mentioned pipelining as an optimization on running programs, and just vaguely mentioned that branching is difficult. Here I will have to elaborate.
            </div>
            <div class="padded-text place-title">
	      When the code branches, the CPU guesses what path the code will take a prefetches along that path. However, if the CPU guesses incorrectly, it would have to rewind and run along the correct path. This can be slow, so, surprisingly, the CPU has been tuned to be right nearly 95% of the time. Initially, I thought that this was obvious since the majority of branches would be jumping to the top of a loop. However, it is more interesting to consider that the branch predictor may have to reason about returns. But still: it might be right more than 95% of the time. And here I was thinking that 50% was good.
            </div>
            <div class="padded-text place-title">
	      However, when the CPU is wrong, it may not reset the cache when it goes back to execute the branch. This can be interesting if the instructions set up the cache so that:
	      <ol>
		<li>Some secret data is in the cache</li>
		<li>Data related to the branching is not in the cache</li>
		<li>The CPU has been mistrained to think that the branch will go one way</li>
	      </ol>
	      Then, the cache might incorrectly have some data the reveals a secret.
            </div>
            <div class="place-title big-title">The Upshot</div>
            <div class="padded-text place-title">
	      The point of including this, particularly in a menagerie of rants about various things "relating to systems programming" is to point out that despite being able to understand assembly, you likely do not know what the computer is really doing. That how the CPU works is really, really hard to reason about. Simply, the point is: keep questioning it -- you don&rsquo;t understand it.
            </div>
	</div>

	  <div id="slide-9">
            <div class="big-title">Better Hash Maps</div>
            <div class="padded-text place-title">
	      This is really a rant about my education, but brings up some useful points. I hope to whine about Hyrum&rsquo;s law and benchmarking enough to make this more than just complaining that I did not understand a hash map implementation from back when I was in data structures.
            </div>
            <div class="padded-text place-title">
	      If you read the last slide (woah you&rsquo;re still reading?! OK, sorry for the Gundam references.) you might be waiting for me to talk about caching. Well, this is that bit.
            </div>
            <div class="big-title place-title">
	      Hashmap Crash Course
            </div>
            <div class="padded-text place-title">
	      Hashmaps are the bread and butter of fast storage and retrieval. The only places that shirk them have other constraints that force them to do so. If you can use a hashmap, it&rsquo;s likely that you should. It gives you this API:
	      <table border="1">
		<tr>
		  <th>Function</th>
		  <th>Functionality</th>
		  <th>Average big-O</th>
		</tr>
		<tr>
		  <td>Insert</td>
		  <td>Puts something in the hashmap. This "something" is usually a "key" and the "value" it maps to.</td>
		  <td>O(1)</td>
		</tr>
		<tr>
		  <td>Update</td>
		  <td>Updates something in the hashmap. This "something" is usually a "key" and the new "value" it maps to.</td>
		  <td>O(1)</td>
		</tr>
		<tr>
		  <td>Get</td>
		  <td>Retrives the value attached to the key.</td>
		  <td>O(1)</td>
		</tr>
		<tr>
		  <td>Delete</td>
		  <td>Removes the key and value that were in the hashmap. Usually this returns the value and sometimes also the key.</td>
		  <td>O(1)</td>
		</tr>
	      </table>
	      If you do not understand this, I should appologise and admit I am not too great at explaining how to use these wonderful data structures since I kind of got used to them before properly understanding how they worked. I think these are difficult to motivate if you are particularly inexperienced in coding. If you have coded much, you might have found yourself needing to related pairs of things and may be this sentence helped something click. I can only hope.
            </div>
            <div class="big-title place-title">
	      Implementing Hash Maps
            </div>
            <div class="padded-text place-title">
	      The rightmost column in the table above should look somewhat magical: <code>O(1)</code> for everything does sound like a scam. The catch is that this is the average case: the worst case for all of those operations is <code>O(n)</code>. The secret sauce is called hashing. You project values into 64-bit integers (nowadays) and use those integers to look in an array.
            </div>
            <div class="padded-text place-title">
	      Hashing is not quite that simple, though, since there is one problem that is common with all implementations of hashmaps: not all values of every type can fit into 64 bits. (Consider strings, particularly those with more than 8 characters, for example.) This leads to a problem with the hashing: every hash function cannot be injective (there will be two keys k1 and k2 where hash(k1) = hash(k2) despite k1 not being the same as k2). Keys that hash to the same thing while being different are called collisions. This would lead to them being placed in the same spot in the array in a hashmap. Implementations tend to differ on how to handle this. In particular:
	      <ul>
		<li>Chaining: placing keys and values into a linked list in the relavant array slot</li>
		<li>Linear probing: placing collisions into the next spot on the array</li>
	      </ul>
            </div>
            <div class="big-title place-title">
	      A First Glance: Is Chaining Better?
            </div>
            <div class="padded-text place-title">
	      Initially, it seems that the chaining approach would be better: since every collision is in an independent linked-list, one collision does not affect any others, and deletions do not make look up too difficult. Consider this sequence:
	      <ol>
		<li><code>insert(k1)</code></li>
		<li><code>insert(k2)</code> (where <code>k2</code> collides with <code>k1</code>)</li>
		<li><code>insert(k3)</code> (where <code>k3</code> hashes "next to" <code>k1</code> and <code>k2</code>)</li>
		<li><code>delete(k2)</code></li>
	      </ol>
	      Naive implementations of linear probing could be stuck: once <code>k2</code> is removed, for correct behavior with <code>k3</code> you&rsquo;d either have to move <code>k3</code> down to where it "belongs" or look through the entire list. This, however, can be alliviated with a simple fix: have a "tombstone" state to mark the ghosts of collisions past. This way, only a few lookups would have to perform a (partial) linear search through the array.
            </div>
            <div class="padded-text place-title">
	      This leaves the question of which one is actually better: it may still seem like chaining is better since it is not only simpler, but has slightly stronger guarantees: you can be a little more sure that collisions will be contained to the array slot (commonly called bucket).
            </div>
            <div class="big-title place-title">
	      Caching: Why Linear Probing is (Sort of) Better
            </div>
            <div class="padded-text place-title">
	      Despite the simplicity of Chaining, there is an implementation called a dense hashmap which turns out to be better (sometimes). There are a few key observations that help. In particular, it&rsquo;s a lot rarer for users of hashmaps to delete things. Usually, hashmaps are built in a function and then queried a bunch. Generally, they may be inserted into as well. This can be intuited from implementations of graph traversals and algorithms. This benefits linear probing with tombstones since the worst case is rarer. But there more, since, recall:
            <div class="big-title center-text">
	      Memory is Slow!
            </div>
            </div>
            <div class="padded-text place-title">
	      This is where the CPU does something smart: it prepares for the memory I/O by having layers of caching. It sucks nearby memory into a cache each time it needs to since it is likely that programs will access nearby memory soon after it accesses the memory being accessed (spatial and temporal locality respectively). Linked lists ruin this since it&rsquo;s hard to ensure that the nodes will be close enough for the cache to suck in adjacent nodes. Arrays, however, work really well for this. Traversing an array can be a lot faster. Another advantage is that the arrays could be traversed via SIMD instructions, particularly when probing for occupied slots.
            </div>
            <div class="padded-text place-title">
	      This can be further optimized as the <a href="https://abseil.io/docs/cpp/guides/container#hash-tables"><code>flat_hash_map</code></a>. This can even be further optimized to incorporate chaining, but we end up reaching an important (tangential) discussion: theorizing only helps so much. At some point, you should just benchmark. Your dataset might have some biases, your CPU, or the memory layouts you end up with could vary. You do not actually know what will perform better until you measure it.
            </div>
	  </div>

	  <div id="slide-10">
            <div class="big-title">Benchmarking</div>
            <div class="padded-text">
	      <i>Not to imply that I have actually done any of this. But do as I say, not as I do.</i>
            </div>
            <div class="padded-text place-title">
	      I hope the last two slides have made it clear that computers are a lot more complicated than you would think. And even then, they are hard to predict. It is definitely odd that the interaction of small predictable rules leads to unpredictable behavior. But such is life. So if you want to know about speed an be sure, benchmark.
            </div>
            <div class="padded-text place-title">
	      The catch is that getting reliable benchmarks is hard. The behavior of various data structures and algorithms depends really heavily on the data you run it on. Sorting is a really important special case about this since it has been studied very heavily.
            </div>
	  </div>

	  <div id="slide-11">
            <div class="big-title">Static Checking, Correctness...</div>
            <div class="padded-text">
	      <i>...and the worst transition in topics ever.</i>
            </div>
            <div class="padded-text big-title">
	      Now for someting Completely different<a href="https://www.youtube.com/results?search_query=now+for+something+completely+different">.</a>
            </div>
            <div class="padded-text place-title">
	      The previous topics were sort of granular, small details. 細かい. They vary by CPU and detail precisely how the computer executes commands and what sorts of tricks it uses. The rest of these slides are really one abstraction layer above: they detail programming language design decisons and how they interact with programming. This can be seen as a lot broader, more opinionated, and (sorta) a move from science to mathematics.
            </div>
            <div class="padded-text place-title">
	      The discussion of programming languages does have measurable hypotheses and long-term experiments, but also tends to lead to less data-dependant and more mathematical facts. Furthermore, it really helps to reason about the compiler as a theorem prover (particularly not for C++). These facts assist coding since when code behaves like math, it tends to be error (and weirdness) free. Once code is weirdness-free, it also becomes easier to optimize. (I will define "weirdness" as it is relevant.)
            </div>
            <div class="padded-text place-title">
	      A key takeaway is that there is a difference between static and dynamic certitude that a program is correct. The point is that static assurances apply to the code and dynamic assurances would apply depending on the data.
            </div>
            <div class="padded-text place-title">
	      Hence, there is an important point to be made about static guarantees: they assure you regardless of the data. This can protect your code from security vulnerabilities and crashes without the need of tests. (Though you <i>should</i> still have unit tests for some sweet dynamic guarantees too.)
            </div>
            <div class="padded-text place-title">
	      This is made even better by the fact that static analysis tools are getting better. They understand more errors and patterns in larger programs. Compilers are getting smarter too.
            </div>
	  </div>

	  <div id="slide-12">
            <div class="big-title">Superior C Syntax</div>
            <div class="padded-text place-title">
	      This is a trend I have seen in quite a few programming languages that starts with this line of C/C++ code: <code><span class="keyword">int</span>* a, b;</code> and asks what the type of <code>b</code> is. Here, many people will have thought that <code>b</code> is an <code><span class="keyword">int</span>*</code>, whereas it is really an <code>int</code>.
            </div>
            <div class="padded-text place-title">
	      Furthermore, consider <code><span class="keyword">typedef void</span>* (*alloc)(<span class="keyword">int</span>,<span class="keyword">int</span>)[2];</code> or any other weird alias of a function pointer type. This is a large complication, to the point where there is <a href="https://cdecl.org/">a website to decipher it</a>. (Exercise: guess what I was trying to forward declare. Suggest some (useful) values of that type.)
            </div>
            <div class="padded-text place-title">
	      That&rsquo;s one of the simpler surface-level issues with C: its syntax makes it easy to run with scissors. Nowadays, having the type after the variable name has become more popular, so <code><span class="keyword">let</span> a, b: * <span class="built-in">int</span></code> would make two pointers two integers. (Actually, I would hope that the notion of a fixed <code><span class="keyword">int</span></code> also vanishes and we move to stating the size in the type like Rust&rsquo;s <code><span class="keyword">i32</span></code>. I also like that the <code><span class="keyword">unsigned</span></code> keyword can be replaced by a (in my opinion) cleaner <code><span class="keyword">u</span></code> prefix.)
            </div>
            <div class="big-title place-title">Bigger Critiques of C</div>
            <div class="padded-text place-title">
	      The above points are important: they would reduce the bugs in code and make the learning curve for some programming languages less steep. But there are bigger fish to fry. And that is mostly what the next sections discuss. I leave you with this link: <a href="https://queue.acm.org/detail.cfm?id=3212479">to a really good writeup</a>.
            </div>
            <div class="padded-text place-title">
	      The most compelling critique to me is the small growth in replacement languages:
	      <ul>
		<li>Zig</li>
		<li>Odin</li>
		<li>Jiyu</li>
	      </ul>
	      (All are pretty small still, but they were made for a reason.) Some trends are:
	      <ul>
		<li>Immutability by default.</li>
		<li title="Get wrecked Golang">Support for Generics.</li>
		<li>(Sometimes.) Closures.</li>
		<li>(Sometimes.) RAII or destruction.</li>
		<li>Better error handling either with panics or a result sum type</li>
		<li>Enums being tagged unions (or at least namespaced)</li>
		<li>Smarter handling of integer overflows or underflows (depending on compilation modes sometimes)</li>
	      </ul>
            </div>
	  </div>

	  <div id="slide-13">
            <div class="big-title">Modules</div>
            <div class="padded-text">
	      <code><span class="keyword">using namespace</span> <span class="built-in">std</span>;</code>
            </div>
            <div class="padded-text">
	      <i>Not really: do not use that and C++ namespaces are not modules</i>
            </div>
            <div class="padded-text place-title">
	      This is (ok, also) at two levels: the C/C++ (and COBOL) use, and how C++20, Rust, and various newer languages do it.
            </div>
            <div class="big-title place-title">Header Files Suck</div>
            <div class="padded-text place-title">
	      I&rsquo;m going to say some things and if you recognise them, it will hurt.
              <div class="padded-text">
	        <i>ODR Violation</i>
              </div>
              <div class="padded-text">
	        <i>Static Initialization Of a Global</i>
              </div>
              <div class="padded-text">
	        <i>Include Guard</i>
              </div>
              <div class="padded-text">
	        <i>Makefile (and automake)</i>
              </div>
	      Hurt yet? Had enough? (I had enough of my own CSS as well as these issues.)
            </div>
            <div class="padded-text place-title">
	      What if I told you you were doing something COBOL does? That is the most egregious and striking example of C/C++&rsquo;s inclusion system, in my opinion.
            </div>
            <div class="padded-text place-title">
	      In COBOL, the included file is called a copybook. And it is literally copied into the file. But wait, there&rsquo;s more:
            </div>
	    <pre>
<span class="keyword">COPY</span> some-procedure <span class="keyword">IN</span> some-library <span class="keyword">REPLACING</span> ==:TAG:== <span class="keyword">BY</span> ==some-example==
	    </pre>
            <div class="padded-text place-title">
	      This is explained in more detail in <a href="https://www.ibm.com/support/knowledgecenter/SS6SG3_4.2.0/com.ibm.entcobol.doc_4.2/PGandLR/ref/rlcdscop.htm">IBM&rsquo;s manual</a>.
            </div>
            <div class="padded-text place-title">
	      My point is that there was a time when copying files in and replacing text was the cutting edge. But modules mean a lot more now. There are some invariants we would like that simple inclusion does not provide. In particular, I would like:
	      <ul>
		<li>Order of imports not to matter</li>
		<li>Modules inside modules</li>
		<li>Ways of specifying access and aliasing</li>
		<li>Everything being in a module</li>
	      </ul>
	      This leads to a lot of issues going away since name collisons will be harder to contrive, and build tools can be significantly simpler since they do not have to worry about the order in which they build things. Programmers would have all the conveniences they need too. But I have a second point:
            </div>
            <div class="big-title place-title">Modules: The Real Encapsulation</div>
            <div class="padded-text place-title">
	      OOP is dead. Well <i>kinda</i>. That is the hot new thing to say. Why you say it and what you really mean does not matter, just like how it never mattered what you said when you "did OOP." But there was a rule in OOP that is quite interesting, and, to some extent important: encapsulation.
            </div>
            <div class="padded-text place-title">
	      Encapsulation is the idea that drivers need not know how engines work. It is the division between understanding what something does and understanding how it works. In code, you do not have to look at the innards of a library to use it. An object would not reveal its fields.
            </div>
            <div class="padded-text place-title">
	      This has been implemented in a sort of mantra that plagues Java code:
            </div>
	    <pre>
<span class="keyword">public class</span> Point3D {
  <span class="keyword">private int</span> x, y, z;

  Point3D(<span class="keyword">int</span> x, <span class="keyword">int</span> y, <span class="keyword">int</span> z) {
    <span class="keyword">this</span>.x = x;
    <span class="keyword">this</span>.y = y;
    <span class="keyword">this</span>.z = z;
  }

  <span class="comment">//Drumroll please...</span>
  <span class="keyword">public int</span> getX(){ <span class="keyword">return</span> x; }
  <span class="keyword">public void</span> setX(<span class="keyword">int</span> x){ <span class="keyword">this</span>.x = x; }
  <span class="keyword">public int</span> getY(){ <span class="keyword">return</span> y; }
  <span class="keyword">public void</span> setY(<span class="keyword">int</span> y){ <span class="keyword">this</span>.y = y; }
  <span class="keyword">public int</span> getZ(){ <span class="keyword">return</span> z; }
  <span class="keyword">public void</span> setZ(<span class="keyword">int</span> z){ <span class="keyword">this</span>.z = z; }
}
	    </pre>
            <div class="padded-text place-title">
	      This is not intended to critique Java as a programming language, but the lack of understanding of the point of encapsulation. The <code>Point3D</code> encapsulates nothing: it is just three integers and a smidge of semantics. It would be deceptive to add any semantics over this class -- it would loose its point. Philosophically, the death of OOP means that coupling data and behavior is no longer fashionable. This moves the responsibility of encapsulation away from the structures that store data (classes, structs, records, or whatever).
            </div>
            <div class="padded-text place-title">
	      Modules can manage the encapsulation instead: instead of objects of hiding fields in them, type erasure (stay tuned!) and simply not exposing the type would help. This can extend to functions, traits (interfaces, concepts, type families, and so on), and even sub-modules.
            </div>
            <div class="padded-text place-title">
	      To me, this is better for two reasons: classes do not end up becoming namespaces in some strange way, and the access specifications are simpler since there are only two and it is easier to trace what is being used where.
            </div>
	  </div>

	  <div id="slide-14">
            <div class="big-title">Compile-Time Programming</div>
            <div class="padded-text">
	      <i>Because everything becomes O(1), of course.</i>
            </div>
            <div class="padded-text place-title">
	      This is also called metaprogramming. That is really what I shall focus on (particularly in the cases (Lisps) where there is not necessarily a compiler involved).
            </div>
            <div class="big-title place-title">Macros</div>
            <div class="padded-text place-title">
	      C/C++ have a notion of preprocessor macros. <a href="http://www.gigamonkeys.com/book/macros-defining-your-own.html#the-story-of-mac-a-just-so-story" title="I wish this story were true">Lisp has something different (as does Rust).</a> Macros are perhaps the simplest metaprogramming: they quite transparently transform code into code. This can get messy, though.
            </div>
            <div class="padded-text place-title">
	      C/C++ preprocessor macros are notorious for being a headache. Consider this:
            </div>
	    <pre>
<span class="keyword">#define</span> SQUARE(x) x*x

<span class="keyword">double</span> vecNorm2D(Vec2D* v) {
  <span class="keyword">return</span> sqrt(SQUARE(v->x) + SQUARE(v->y));
}
	    </pre>
            <div class="padded-text place-title">
	      Looks cool, right? <code>SQUARE</code> might seem like it is acting as a sort of "function" that, at compile-time, puts in the code to square something. Seems awesome, but this has drawbacks. A whole list of them:
	      <ul>
		<li>The lack of type safety</li>
		<li>The weirdness of predence rules (consider that <code>SQUARE(x + 1)</code> computes <code>x + 1 * x + 1</code>)</li>
		<li>The silliness of string matching (if you <code><span class="keyword">#define</span> PI 3.1415</code>, <code>APPLE_PIE</code> could become mangled into <code>APPLE_3.1415E</code>)</li>
		<li>The lack of hygiene (consider <code><span class="keyword">#define</span> INVENT(v) <span class="keyword">int</span> x = v;</code> which dirties the namespace where it is called to include some variable)</li>
	      </ul>
	      These can be mitigated by good conventions in C/C++ and Lisps. (Clojure, for instance, has <code>gensym</code> to ensure that values do not pollute the namespaces.) Rust is stricter, not only in limiting the complexity of macros (making them more local AST transformations unless you implement a procedural macro which is really Rust code that acts on a compiler-provided token stream), but also in the capability since macros cannot (yet) define values or implement interfaces of types.
            </div>
            <div class="padded-text place-title">
	      Some languages use these ideas for conditional compilation too. This is important in cases where programs are compiled to run on different systems. Different systems may label things differently or simply include or exclude features. I conflate these since the C/C++ and Rust implementations of this (which are the only ones I know) use conditionals that can look similar to the macro invocation. Rust also integrates this with its build system, though, which is an essential difference (OK, if you wanna brave <code>-D</code> flags, you <i>could</i> say C/C++ build systems ("systems") include it).
            </div>
            <div class="big-title place-title">GADTs And Stuff</div>
            <div class="padded-text place-title">
	      GADTs are another way to get the compiler to do a lot of work for you. There is a different focus here, though, since GADTs are not directly about code generation. GADTs are special types that specify other types in their constructors. They can change behavior depending on the types they wrap. That is, they really start to look at generic types as functions into types, allowing the result to vary based on any input.
            </div>
            <div class="padded-text place-title">
	      This is perhaps the more complex, theoretically rigorous way to understand Rust's const generics, C++'s non-type template parameters, and C++'s template specialization, and I will cover a simple view on them later, but if it was not already apparent to you, I like the sight of my own typing (like I like the sound of my own voice at times), so I shall have a section on GADTs anyway.
            </div>
	    <div class="collapsible-container place-title padded-text">
	      <div class="padded-text place-title">
		I'm so serious about how skippable this is that I will just let you skip: <span class="collapse-handle" title="Seriously, I wrote the 20 lines of JS for it too (and then refactored it to an elegant 40... did I say refactored, I meant added pointless features)">just collapse the content here.</span>.
	      </div>
              <div class="padded-text place-title collapsible">
		Since the theory cat is out of the bag (not Shrodinger&rsquo;s cat, my theoretical cat), I should also admit that I will use Haskell for the time being. Since you may have realized that my explanations are impatient gobs of unedited text, you may want to skip this or read a little on GADTs in Haskell before proceeding. I will develop the example that introduced me to GADTs, not the one discussed in <a href="https://en.wikibooks.org/wiki/Haskell/GADT#:~:text=Generalized%20algebraic%20datatypes%2C%20or%20simply,the%20types%20of%20the%20constructors." title="trust me, this is a better explanation than one I can give">the Haskell wiki.</a> Before that, however, I want to detour into HoTT.
              </div>
              <div class="place-title collapsible" style="color:white">HoTT Stuff</div>
              <div class="padded-text place-title collapsible">
		HoTT means "homotopy type theory," and most of the time, the "type theory" part is the more important part for programming. The "homotopy" part only tangentially comes up and is brought up here mostly for a pun in the title (though technically, there's some refls that Haskell will need later on, so may be there's <i>kinda</i> homotopy?).
              </div>
              <div class="padded-text place-title collapsible">
		So we can reduce this to a discussion of just type theory. (Sort of meaning any intuitionistic (I think) type theory.) There are some <a href="modal.html#types" title="See, the sight of my own writing style">really beautiful bits I already ranted about,</a> but for GADTs, I'd like to draw an equivalence to one thing: product types. Not the garden-variety <code>AxB</code> stuff, but the type theoretic big pi-notation, that is, <code title="I'm too lazy to MathJAX or whatever">\prod_{x \in X} A(x)</code>. Normally, we programmers are weirdos who work with <code title="OK, I tried to get you a mathcal">\prod_{x \in \mathcal{<i>U</i>}} A(x)</code>, which you need a nested universe structure for and doesn't really come up in proofs. But consider more: consider what you could do with something like <code>\prod_{l \in Nat, T \in \mathcal{<i>U</i>}} List(l, T)</code>. If you know C++, this is <code>std::array<T, l></code>. Except, the compiler really reasons about the <code>l</code> and assures operations. Let&rsquo;s work through one.
              </div>
              <div class="padded-text place-title">
		This is mostly for my ego (and own future reference) so feel free to <span class="collapse-handle" title="If this seems hamfisted, it is because this sentence actually exists more for me to test the cool JS trick that hides all the collapsible kids in here. I hope it will work across slides too, but who knows if another slide will have an aside so long.">skip.</span>
              </div>
              <div class="padded-text place-title collapsible">
		Now that you have two <span title="Read: demos of my sick JS skills">disclaimers</span>, let me steamroll through some Haskell. I'm going to focus on the <code><span class="keyword">data</span></code> declaration with GADTs first. Normally, <code class="keyword">data</code><!-- Shit that works--> begins the declaration of a sum type (tagged union, discriminated union, and what Rust calls an <code class="keyword">enum</code>). Hence, saying something like <code><span class="keyword">data</span> GoodWeekday = SATURDAY | FRIDAY</code> is <span title="and war on the bourgeois">declaring an enum of two days</span>. To add a generic, we put it before the <code>=</code> and use it after, like: <code><span class="keyword">data</span> Option a = Some a | None</code> (that being Rust's wording of Haskell's <code class="built-in">Maybe</code>). This still is not the product type. For that we need more and I'm going to just jump in (adding a comment or two to help you follow).
              </div>
	      <pre class="collapsible place-title">
<span class="comment">{-# LANGUAGE DataKinds, KindSignatures, GADTs,</span>
<span class="comment">  TypeFamilies, PolyKinds #-}</span>
<span class="comment">-- DataKinds lets us define our own kinds (types of types)</span>
<span class="comment">-- KindSignatures allows the * -> * sort of notation,</span>
<span class="comment">-- TypeFamilies let us express functions on our kinds,</span>
<span class="comment">-- PolyKinds lets us express functions about our kinds,</span>
<span class="comment">-- and GADTs adds... well, GADTs.</span>

<span class="comment">-- A kind for natural numbers. ZNat is 0, SNat is the next one.</span>
<span class="keyword">data</span> Nat :: * <span class="keyword">where</span>
  ZNat :: Nat
  SNat :: Nat -> Nat

<span class="comment">-- A fixed length vector. </span>
<span class="comment">-- This takes the length as the second parameter.</span>
<span class="comment">-- The property of Cons producing a vector one longer is key.</span>
<span class="keyword">data</span> FixedVec :: * -> Nat -> * <span class="keyword">where</span>
  Empty :: FixedVec a ZNat
  Cons :: a -> FixedVec a n -> FixedVec a (SNat n)
	      </pre>
              <div class="padded-text place-title collapsible">
		Since "kinds" came up, I'll mention that they're types of types: the higher universe we need when talking of functions on types. I like to think of it as the requisite Russell's paradox dodging you always need in a theoretical foundation of mathematics: your foundational object can't contain all instances of itself (sorta, usually). We can't have the type of all types, so we have the kind (<code>*</code>) of all types.
              </div>
	      <pre class="collapsible place-title">
<span class="comment">-- Small complaint: it was hard to find the right syntax.</span>
<span class="keyword">type family</span> Plus (x :: Nat) (y :: Nat) :: Nat
<span class="keyword">type instance</span> Plus ZNat     m = m
<span class="keyword">type instance</span> Plus (SNat n) m = SNat (Plus n m)

<span class="comment">-- GHC just figures this out.</span>
fconcat :: FixedVec a n -> FixedVec a m -> FixedVec a (Plus n m)
fconcat Empty       ys = ys
fconcat (Cons x xs) ys = Cons x $ fconcat xs ys
	      </pre>
              <div class="padded-text place-title collapsible">
		A lot of what follows is thanks to <a href="https://stackoverflow.com/a/50788119" title="Hasochism is my new favorite word.">this SO post.</a>
              </div>
	      <pre class="collapsible place-title">
<span class="comment">-- Brings in the :~: type-level equality</span>
<span class="keyword">import</span> Data.Type.Equality
		
<span class="comment">-- Brings the Nat kind into the type universe.</span>
<span class="keyword">data</span> ReifyNat (n :: Nat) <span class="keyword">where</span>
  Zeify :: ReifyNat ZNat
  Seify :: ReifyNat n -> ReifyNat (SNat n)

<span class="comment">-- Brings the vector lenghts into the type universe.</span>
reifyVecLen :: FixedVec a n -> ReifyNat n
reifyVecLen Empty       = Zeify
reifyVecLen (Cons _ xs) = Seify $ reifyVecLen xs

<span class="comment">-- The proof of 1 + (x + y) = x + (y + 1).</span>
<span class="comment">-- Base case: 1 + (0 + 0) = 0 + (0 + 1)</span>
sumSuccRight :: ReifyNat x -> ReifyNat y
  -> (SNat (Plus x y)) <span class="built-in">:~:</span> (Plus x (SNat y))
sumSuccRight Zeify     Zeify     = Refl
sumSuccRight (Seify n) Zeify     = apply Refl
  $ sumSuccRight n Zeify
sumSuccRight Zeify     (Seify n) = apply Refl
  $ sumSuccRight Zeify n
sumSuccRight (Seify m) (Seify n) = apply Refl
  $ sumSuccRight m (Seify n)

<span class="comment">-- GHC needs that (1 + (x + y)) = (x + (y + 1)).</span>
<span class="comment">-- You'll note that that's not how we defined +.</span>
fdup :: FixedVec a n -> FixedVec a (Plus n n)
fdup Empty       = Empty
fdup (Cons x xs) = <span class="keyword">case</span>
  sumSuccRight (reifyVecLen xs) (reifyVecLen xs) <span class="keyword">of</span>
    Refl -> Cons x (Cons x (fdup xs))
	      </pre>
              <div class="padded-text place-title collapsible">
		The inductive cases above are non-trivial and this snippet brings in homotopies. The <code class="built-in">:~:</code> type (yeah, <code>TypeOperators</code> extension go brr) is the identity type that much of HoTT fixates on. It has one constructor called <code>Relf</code>. This <code>Refl</code> is the compiler marking that it can show that two types are equal. The other non-trivial thing is the use of <code>apply</code>. I'm going to butcher this with words when a diagram (in fact "geometric" intuition) would really help. <code>apply</code> takes two <span title="I'll hide this in the alt-text: this is the inverse of function extensionality (which Haskell also has -- C++ take notes)">equal functions</span> and two equal arguments and proves that the outputs of the functions on the arguments are equal. Hence, the inductive cases are really saying:
		<ol>
		  <li>Base case: <code>1 + (0 + 0) = 0 + (0 + 1)</code>.</li>
		  <li><code>f(x) = x + 1</code> equals itself.<i>This isn't directly said, but pronounced as <code>Refl</code> since it is the fact that <code>SNat = SNat</code></i></li>
		  <li><code>1 + ((n + 1) + 0) = (n + 1) + (0 + 1)</code> since 2 and <code>n = 0</code> is the base case.</li>
		  <li>The next part of the function counts the other parameter down, showing <code>1 + 0 + (m + 1) = 0 + ((m + 1) + 1)</code> and the same base case (using <code>apply</code> thanks to 2).</li>
		  <li>The final case counts down the first parameter, noting the same fact as 3, but for m (second parameters) more than 0.</li>
		</ol>
		That about wraps up this skippable type theory side-rant (that's probably reaching the length of my original type theory rant). Here are some links: <a href="https://github.com/hemangandhi/derpspace/blob/master/Haskell/gadt.hs">the whole Haskell file</a> and <a href="https://github.com/hemangandhi/derpspace/blob/master/rust/FixedVec.rs">a similar thing in Rust</a> (note that the Rust one needs so massaging for the correct lifetimes -- the simplest thing to do is make everything needed a <code class="keyword">'static</code>, but that's <span title="OK, and it probably never will be">not useful enough</span> for me to actually want to put it as my final version). This is one way to look at the next section and I really hope more theoretically inclined people actually unify this GADT approach with compile-time programming as we know it in C++.
              </div>
            </div>
	    <div class="collapsible-container place-title padded-text">
              <div class="padded-text place-title">
		Actually, there's a different side-rant I'd like to give before discussing <code class="keyword">constexpr</code>. Again, <span class="collapse-handle">feel free to skip.</span>
              </div>
              <div class="place-title collapsible" style="color:white">TMP does not GADTs Make</div>
              <div class="padded-text place-title collapsible">
		TMP (template metaprogramming) is the C++ construct that is a small functional programming language with pattern matching for conditionals and recursion (yes, it's Turing complete) that simplifies some C++ code generation. I'll spare you an example. All I mean to say here is that formally, TMP does not add GADTs into C++. (Concepts in C++20 might, but I cannot be too sure: since they don't have to be complete, they might not reach the same theorem-proving strength.)
              </div>
              <div class="padded-text place-title collapsible">
		There are a few explanations for this. The one I personally found is that the C++ compiler does not prove any facts about the templates it sees: it merely stashes them for later use. You can put in some impossible nonsense in a template and have a compiling C++ program. The errors arise when, in the buildable unit, there is a use of the template (an instance) that the compiler cannot understand. The compiler tries to fill out every template for each of its instances and only raises errors when this "filling out" (expansion, instantiation) fails. GHC does not do that with GADTs: it actually ensures that the <code>Nat</code>s in the <code>FidexVec</code>, despite being unused, actually are the correct <code>Nat</code>s each time. Rustc does the same thing with the <code>PhantomData</code> marker and phantom types (where you specifically make types stronger than their representations as seen by the CPU).
              </div>
	    </div>
            <div class="big-title place-title"><code class="keyword">constexpr</code> and Compile-time Programming</div>
            <div class="padded-text place-title">
	      It's strange to basically repeat the title of the slide so close to the end. <i>Cinema sins voice: roll credits.</i> But, there's no better way to express this. This type of programming does not (yet) emphasize code generation or verification. This really ends up filling in some gaps that low-level programming needs: easier initialization and computation of constants. The essential idea is that some constants need a little nudge to be ready for the lifetime of the program. Something like the list of the first <code>n</code> primes or some other product. Even complex types like a lookup table (or strings or a lookup table of strings). There are a few more complications: such as how many copies of the constant value the compiler may create (see C++'s <code class="keyword">inline constexpr</code>), and the fact that <code class="keyword">constexpr</code> functions and constructors can be run at runtime.
            </div>
            <div class="padded-text place-title">
	      There are other instances of this. Really, compilers do this more than just when you tell them to: there's an optimization called constant propagation that does this sort of thing as much as possible. Furthermore, other programming languages have equivalents to <code class="keyword">constexpr</code>: Zig has <code class="keyword">comptime</code> as a keyword for function parameters known at compile time (these serve as means for adding generics too), <a href="https://without.boats/blog/shipping-const-generics/">const generics</a> are coming to Rust to complement <a href="https://doc.rust-lang.org/nightly/edition-guide/rust-next/const-fn.html">const fns</a>. It's worth noting that this is the simpler way to reason about array types too (that really should be qualified by their lengths).
            </div>
	  </div>

	  <div id="slide-15">
            <div class="big-title">RAII</div>
            <div class="padded-text">
	      <i>Resource Allocation is Initialization</i>
            </div>
            <div class="padded-text">
	      <i>What a wonderful phrase</i>
            </div>
            <div class="padded-text">
	      <i>Resource Allocation is Initialization</i>
            </div>
            <div class="padded-text">
	      <i>Ain't no passing craze!</i>
            </div>
            <div class="padded-text">
	      <i>It means no worries, for your resources.</i>
            </div>
            <div class="padded-text">
	      <i>It's our problem-free philosophy,</i>
            </div>
            <div class="padded-text">
	      <i>Resource Allocation is Initialization</i>
            </div>
            <div class="padded-text place-title">
	      It really is. The incantation doesn't sound like Hakuna Matata, but if you're used to it, it will feel like that. This originates in C++, so my discussion will be focuessed on that. Rust has the same concept too, but it's easier to me to explain it in C++. In C++, when you declare a variable, you allocate memory for it. Consider:
            </div>
	    <pre>
Hyena ed;
<span class="keyword">if</span> (be_prepared()) {
  ed = banzai;
} <span class="keyword">else</span> {
  ed = shenzi;
}
	    </pre>
            <div class="padded-text place-title">
	      Besides being a nonsensical <span title="LionKing&">film reference</span>, this snippet demonstrates something important about C++: the default constructor of <code>ed</code> was run -- hence, it was allocated. This <i>could</i> hold some resources (not that hyenas held much in the film). And there was only one way to get these resources: initialization. In a good API, the way to get a resource would be to initialize a handle. Then when that handle is destroyed (like any good leak-free program must), the destructor can release the resource. Consider (<a href="#slide-7">as promised earlier</a>):
            </div>
	    <pre>
<span class="keyword">#include</span> <span class="built-in">&ltatomic&gt</span>

<span class="keyword">template</span> &lt<span class="keyword">class</span> T&gt
<span class="keyword">class</span> Locked {
 <span class="keyword">public</span>:
  <span class="keyword">class</span> HeldValue {
   <span class="keyword">public</span>:
    HeldValue(T* h, <span class="built-in">std::atomic</span>&lt<span class="keyword">bool</span>&gt* m) {
      <span class="keyword">bool</span> f = <span class="keyword">false</span>;
      <span class="keyword">while</span> (!m-&gtcompare_exchange_strong(f, <span class="keyword">true</span>));
      held_ = h;
      mutex_ = m;
    }
    T& <span class="keyword">operator</span>*() { <span class="keyword">return</span> *held_; }
    T* <span class="keyword">operator</span>-&gt() { <span class="keyword">return</span> held_; }
    ~HeldValue() { *mutex_ = false; }

   <span class="keyword">private</span>:
    T* held_;
    <span class="built-in">std::atomic</span>&lt<span class="keyword">bool</span>&gt* mutex_;
  };

  Locked(T t) : locked_(t), mutex_(false) {}
  HeldValue Lock() { <span class="keyword">return</span> HeldValue(&locked_, &mutex_); }
  <span class="keyword">bool</span> IsHeld() { <span class="keyword">return</span> !mutex_; }

 <span class="keyword">private</span>:
  <span class="built-in">std::atomic</span>&lt<span class="keyword">bool</span>&gt mutex_;
  T locked_;
};

<span class="keyword">void</span> useLockedThingy(Locked&lt<span class="keyword">int</span>&gt* p) {
  Locked&lt<span class="keyword">int</span>&gt::HeldValue grabbed = p->Lock();
  (*grabbed)++;
}
	    </pre>
            <div class="padded-text place-title">
	      I think it's important to emphasize how this works. So here's the assembly, since that's how I'd like to explain it. (And <a href="https://gcc.godbolt.org/">gcc.godbolt.org</a> is really cool.)
            </div>
	    <pre>
useLockedThingy(Locked&ltint&gt*):
        <span class="keyword">mov</span>     <span class="built-in">BYTE PTR [rsp-1]</span>, 0
        <span class="keyword">mov</span>     <span class="built-in">edx</span>, 1
.L3:
        <span class="keyword">movzx</span>   <span class="built-in">eax, BYTE PTR [rsp-1]</span>
        <span class="keyword">lock cmpxchg</span> <span class="built-in">BYTE PTR [rdi], dl</span>
        <span class="keyword">je</span>      .L4
        <span class="keyword">mov</span>     <span class="built-in">BYTE PTR [rsp-1], al</span>
        <span class="keyword">jmp</span>     .L3
.L4:
        <span class="keyword">add</span>     <span class="built-in">DWORD PTR [rdi+4]</span>, 1
        <span class="keyword">xor</span>     <span class="built-in">eax, eax</span>
        <span class="keyword">xchg</span>    <span class="built-in">al, BYTE PTR [rdi]</span>
        <span class="keyword">ret</span>
	    </pre>
            <div class="padded-text place-title">
	      This is really amazing: you'll notice that the notion of the <code>HeldValue</code> entirely disappears: all the functions that were called get inlined to just the five bytes that are the <code class="keyword">int</code> and the <code class="keyword">bool</code> as the values pointed to by <code>rdi</code>.
            </div>
            <div class="padded-text place-title">
	      The most wonderful thing, though, is that despite having no increased cost, the right thing happens: the <code><span class="keyword">xchg</span> <span class="built-in">al, BYTE PTR [rdi]</span></code> releases the mutex.
            </div>
            <div class="padded-text place-title">
	      RAII doesn't just apply to mutexes and memory, but files, sockets, database connections, and pretty much anything that you'll cease to need at a deterministic time.
            </div>
	    <div class="padded-text">
	      <i>In the memory, unmanaged memory,</i>
	    </div>
	    <div class="padded-text">
	      <i>Resources sleep tonight.</i>
	    </div>
	    <div class="padded-text">
	      <i>Run destructors, clean up garbage,</i>
	    </div>
	    <div class="padded-text">
	      <i>Resources sleep tonight.</i>
	    </div>
	  </div>

	  <div id="slide-16">
            <div class="big-title">Linear Types</div>
            <div class="padded-text">
	      <i><a href="https://youtu.be/ApuFuuCJc3s">Sage advice from Madagascar (the movie).</a></i>
            </div>
            <div class="padded-text place-title" title="OK, and I hamfisted a catchy earworm.">
	      So linear types aren't really just about move semantics. This is another wedding of some concepts and I think really go hand-in-hand. Move semantics help use linear types and linear types help motivate the use of linear semantics. But I'm really just going to mention that moves exist as a thing. Bjarne Stoustroup has a <a href="https://youtu.be/86xWVb4XIyE?t=2395">good brief explanation of the issue</a>. Since this <i>is</i> about linear types, you should assume that a lot of things use move semantics.
            </div>
            <div class="padded-text place-title">
	      Other than that, it's worth mentioning the more important linear types: <code class="built-in">std::unique_ptr</code> in C++ and any type that isn't a <code class="built-in">Copy</code> in Rust. Haskell also has linear types. C++ and Haskell support linear types as a special subset of the semantics, but Rust makes it the default.
            </div>
            <div class="padded-text place-title">
	      The idea of a linear type is that it is produced and then consumed. In a way, it's like thinking of values as molecules in chemistry. This, to me, is more like how resources should work in computers too since you don't get copies for free. <a href="modal.html#linear">I've discussed this before too.</a>
            </div>
	  </div>

	  <div id="slide-17">
            <div class="big-title">Error Handling</div>
            <div class="padded-text place-title">
	      This is a trend I've seen that is pretty interesting. Rust has most of what I'm on about. Golang does too, and C++ supports it, but I know very little about exceptions and think that they're a philosophical anda syntactic mess. So first I'll bash them and then present the (monadic) light.
            </div>
            <div class="padded-text place-title">
	      Exceptions are a really weird term for errors in a program. Pragmatically, there are two types of errors: something the program can handle, and something that the program cannot handle. The former is a reasonable candidate for error handling, the latter being something the OS should resolve on the program's behalf, perhaps terminating it. Consider some invalid input or a message from the network failing to parse versus a segmentation fault or running out of memory. The word "exception" has an implication: that something exceptional occured. This is a really weird conflation of the subjective divide on what errors programs should and should not be able to recover from. If the program can recover from the error, just how "exceptional" was the behavior? Are we supposed to expect exceptions to our rules? These semantics are strange to me. I'm sure the word made more sense earlier, but now, we have recoverable errors and crashes, and I don't think we need to really care about further distinctions.
            </div>
            <div class="padded-text place-title">
	      Furthermore, semantics aside, I also think that the syntax of exceptions is invariably clumsy. You end up with a separate exit from a function, separate handling of the errors and various really strange workarounds for "exceptional exits." In particular, when trying to catch an exception, the control flow becomes really strange: if you must run code before exiting the function, you need a special goto now that's just relabelled as <code class="keyword">finally</code> (at least in Java which also now has some sort of RAII scoped try thingy that will cleanup resources for you). This adds a lot of mental overhead to a programming language, in my opinion. It is worsened by the notion of checked and unchecked exceptions (another quirk in the semantics too) and odd conventions like <a href="https://en.cppreference.com/w/cpp/language/noexcept_spec"><code class="keyword">noexcept</code>'s details</a>. I think these facts make error handling unsightly -- much uglier than it needs to be.
            </div>
            <div class="padded-text place-title">
	      Now that I've bashed one approach, let me be even more opinionated by presenting the solution I like: the <code class="built-in">Result</code> built-in sum type. Rust has this. This type is great for various reasons: there is no overhead in terms of new syntax (except may be the <code>?</code> operator, but that's a success story if anything), no notion of unchecked exceptions, no extra changes in control flow, and no odd semantic implications about "exceptional behavior." The <code class="built-in">Result</code> type is also really well-understood in Haskell's <code class="built-in">Either</code> which provides a lot of useful functions for proceeding until the first error, or transforming the success state if there is one, or even transforming the error if that's there. This can lead to some beautiful code since you can chain operations rather elegantly with either <code>?</code> being used a lot or <a href="https://doc.rust-lang.org/std/result/enum.Result.html#method.and_then" title="Haskellers will know this as >>=">the <code>.and_then</code> function.</a>
            </div>
            <div class="padded-text place-title">
	      Such a sum type is no panacea: the types of errors are hard to extend when working with a sum type, but this is an area of <a href="https://doc.rust-lang.org/beta/std/error/trait.Error.html">active work in Rust.</a>
            </div>
	  </div>

	  <div id="slide-18">
            <div class="big-title">Dispatch</div>
	    <div class="padded-text"><i>How to Stop Worrying and Generically Program</i></div>
            <div class="padded-text place-title">
	      This is about static and dynamic dispatch. Broadly, dispatch is about knowing which concrete function to call for abstract types. Consider (in C++):
            </div>
	    <pre>
<span class="keyword">#include</span> <span class="built-in">&lt;string&gt;</span>

<span class="keyword">class</span> Slide {
<span class="keyword">public</span>:
  <span class="keyword">virtual</span> <span class="built-in">std::string</span> GetText() = 0;
  <span class="keyword">virtual</span> ~Slide();
};

<span class="keyword">class</span> LongSlide : <span class="keyword">public</span> Slide {
<span class="keyword">public</span>:
  <span class="built-in">std::string</span> GetText() <span class="keyword">override</span>;
  <span class="keyword">int</span> GetScrollLevel();
};
	    </pre>
            <div class="padded-text place-title">
	      This could lead to vague code: if I have a <code>Slide * s</code> and I <code>s->GetText()</code>, the exact implementation of <code>GetText</code> could be vague. If I added more child classes under <code>Slide</code>, the choices may abound. There are two ways the compiler may fix this:
	      <ul>
		<li>Static dispatch: where different functions are generated every time a choice is made and so there is excatly one function every time. This can also be called monomorphization.</li>
		<li>Dynamic dispatch: where every object carries a small table of function pointers disambiguating which function you'd call.</li>
	      </ul>
	      There's a tradeoff worth knowing here: dynamic dispatch has at least 2 (since some lookups in C++ may defer to parent classes) jumps that could really slow the CPU down, but static dispatch can bloat the binary, also slowing down execution. The above example with <code>Slide</code>s actually does a dynamic dispatch (as of December 2020 on GCC with an <code>-O3</code>). C++ templates may do static dispatch, Rust's behavior varies based on the way you're using traits, how many traits you're using, and how large the traits are (in instances and probably number of functions). Java does something like what Rust does.
            </div>
	  </div>

	  <div id="slide-19">
            <div class="big-title">From Closures to Type Erasure</div>
            <div class="padded-text place-title">
	      Consider this: it's the mid 2000s and C++ has a standard (finally), but it's just a record of what C++ has become. There's a great library, and it provides much: <code class="built-in">&lt;algorithm&gt;</code>. It's really neat since a lot of array and vector transformations are easier -- more readable and things you don't need to rewrite repeatedly. Consider, however, the C code that <code>lfind</code> is based on: <code><span class="keyword">void </span>* lfind (<span class="keyword">const void</span>* key, <span class="keyword">const void</span>* base, <span class="built-in">size_t</span> nitems, <span class="built-in">size_t</span> size, <span class="keyword">int</span> (*compar) (<span class="keyword">const void</span>*, <span class="keyword">const void</span>*));</code> which, the bad function pointer syntax notwithstanding, makes the <code>compar</code>ator have to be a static constant. Suppose that we wanted to sort the same range with more or less the same comparator? If we wanted these comparators to vary, we'd need a different functions. For instance, if the <code><span class="keyword">void</span>*</code> referred to names, and we only wanted to find by first names or last names, and sometimes by the whole name, this would be three functions.
            </div>
            <div class="padded-text place-title">
	      C++98 makes this a little easier since we could have what C++ calls a functor (it's sort of abuse of notation, but I'm not talking about real functors, so I'll use the C++ terminology). A functor is a callable with data, a <code class="keyword" title="or class, but you get the gist">struct</code> that overloads <code class="keyword">operator()</code>. So consider the C++ <code class="built-in">std::find_if</code>. In C++20 (or C++23  when this gets more standard), this would look like <code><span class="keyword">template</span>&lt;<span class="built-in">Iterator</span> It, <span class="built-in">FunctionType</span>&lt;<span class="keyword">bool</span>, It::ValueType&gt; Fn&gt; It <span class="built-in">std::find_if</span>(It begin, It end, Fn compar);</code> (which seems like jumping the gun since I am still really talking about C++98 where this would just be a template with nothing too fancy). In this case, you'd encode the logic of the three comparators (first name only, last name only, or whole name from the example above) into a <code class="keyword" title="I recommend a struct since I see them as emphasis on 'this type is just a wrapper or functor, not something with important long-term invariants' in C++">struct</code>. The really neat part about this is that the compiler can inline a lot of the notion of there having been a struct at all.
            </div>
            <div class="padded-text place-title">
	      C++11 made this situation better by adding a really nice syntactic sugar for functors: lambdas. The notion of capturing codifies the state the functor would've been initialized with and the lambda body takes the place of the <code class="keyword">operator()</code>. This is getting better and better as C++ evolves, but there is more to the puzzle. The functor struct used to be a concrete type. Lambdas are also supposed to be compiler-generated (opaque) types. This brings up an issue: what if I want to write my own higher-order function? Am I forced to add a template? Does that have to propagate all the way down?
            </div>
            <div class="padded-text place-title">
	      There's some alternate magic: <code class="built-in">std::function</code>. This can wrap any callable, but you can peer behind that curtain (other than the syntactic sugar that lets you write the return type first -- I have no clue what that is). There are two ways to do this. C++17 and earlier needed <code class="built-in">std::enable_if</code> hacks. But now I present another way to deal with this as of C++20's draft (using clang-trunk in December 2020):
            </div>
	    <pre>
<span class="keyword">#include</span> <span class="built-in">&lt;concepts&gt;</span>

<span class="keyword">template</span> &lt;<span class="keyword">typename</span> F, <span class="keyword">typename</span> RT, <span class="keyword">typename</span>... Args&gt;
<span class="keyword">concept</span> Function = <span class="keyword">requires</span> (RT r, Args... a) {
  {F{}(a...)} -&gt; <span class="built-in">std::convertible_to</span>&lt;RT&gt;;
  <span class="built-in">std::copy_constructible</span>&lt;F&gt;;
};

<span class="comment">// Technically useless, but this is what C++17 (sorta) had as its std::function</span>
<span class="keyword">template</span> &lt;<span class="keyword">typename</span> F, <span class="keyword">typename</span> RT, <span class="keyword">typename</span>... Args&gt;
<span class="keyword">requires</span> Function&lt;F, RT, Args...&gt;
<span class="keyword">class</span> MyStdFunction {
<span class="keyword">public</span>:
  MyStdFunction(F f) : f_(f) {}
  RT <span class="keyword">operator()</span>(Args... a) {
      f_(a...);
  }
<span class="keyword">private</span>:
  F f_;
};
	    </pre>
            <div class="padded-text place-title">
	      Amazingly, this makes the "good" type declaration of <code class="built-in">std::find_if</code> that I wrote above fairly accurate. At the risk of overusing concepts (and not discussing the boring old <code class="built-in">std::enable_if</code>-based classes in C++17), here's an iterator concept too:
            </div>
	    <pre>
<span class="keyword">template</span> &lt;<span class="keyword">typename</span> It&gt;
<span class="keyword">concept</span> IteratorForFind = <span class="keyword">requires</span>(It i) {
  <span class="keyword">typename</span> It::value_type;
  { *i } -&gt; <span class="built-in">std::convertible_to</span>&lt;<span class="keyword">typename</span> It::value_type&gt;;
  { i++ } -&gt; <span class="built-in">std::convertible_to</span>&lt;It&gt;;
};
	    </pre>
            <div class="padded-text place-title">
	      This isn't <i>quite</i> the right thing. The next slide is that, because I got distracted and the concepts are way cooler than the class-based old type erasure. Rust has it too: <a href="https://doc.rust-lang.org/std/ops/trait.Fn.html">See the <code class="built-in">std::ops::Fn</code> trait.</a>
            </div>
	  </div>

	  <div id="slide-20">
            <div class="big-title">C++20 Concepts: A Detour Because I Can</div>
            <div class="padded-text place-title">
	      So this started with baby type erasure:
            </div>
	    <pre>
<span class="keyword">#include</span> <span class="built-in">&lt;concepts&gt;</span>

<span class="keyword">template</span> &lt;<span class="keyword">typename</span> F, <span class="keyword">typename</span> RT, <span class="keyword">typename</span>... Args&gt;
<span class="keyword">concept</span> Function = <span class="keyword">requires</span> (RT r, Args... a) {
  {F{}(a...)} -&gt; <span class="built-in">std::convertible_to</span>&lt;RT&gt;;
  <span class="built-in">std::copy_constructible</span>&lt;F&gt;;
};

<span class="keyword">template</span> &lt;<span class="keyword">typename</span> It&gt;
<span class="keyword">concept</span> IteratorForFind = <span class="keyword">requires</span>(It i) {
  <span class="keyword">typename</span> It::value_type;
  { *i } -&gt; <span class="built-in">std::convertible_to</span>&lt;<span class="keyword">typename</span> It::value_type&gt;;
  { i++ } -&gt; <span class="built-in">std::convertible_to</span>&lt;It&gt;;
};
	    </pre>
            <div class="padded-text place-title">
	      To get the <a href="https://gcc.godbolt.org/">compiler explorer (as of December 2020, clang trunk, <code>--std=c++2a -O3</code>)</a> to output <i>something</i>, I added (rather naturally if I say so myself):
            </div>
	    <pre>
<span class="keyword">template</span> &lt;<span class="keyword">typename</span> It, <span class="keyword">typename</span> Comp&gt;
<span class="keyword">requires</span> IteratorForFind&lt;It&gt; && Function&lt;Comp, <span class="keyword">bool</span>, <span class="keyword">typename</span> It::value_type&gt;
It my_find_if(It begin, It end, Comp c) {
  <span class="keyword">for</span>(; begin != end && !c(*begin); begin++);
  <span class="keyword">return</span> begin;
}

<span class="keyword">int</span> * find_int(<span class="keyword">int</span> n, <span class="keyword">int</span>* arr, <span class="keyword">int</span> key) {
    <span class="keyword">return</span> my_find_if(arr, arr + n, [key](<span class="keyword">int</span> i) { <span class="keyword">return</span> i == key;});
}
	    </pre>
            <div class="padded-text place-title">
	      This doesn't compile since you can't pronounce <code><span class="keyword">int</span> *::value_type</code>. I tried to do some template voodoo to make that work with a "concept specialization" (yes it's a thing, you can now TMP with higher predicates UwU). After some finnagling, and giving up on the <code>value_type</code> being handed to me, I did get this to compile to a tidy loop:
            </div>
	    <pre>
<span class="keyword">#include</span> <span class="built-in">&lt;concepts&gt;</span>

<span class="keyword">template</span> &lt;<span class="keyword">typename</span> F, <span class="keyword">typename</span> RT, <span class="keyword">typename</span>... Args&gt;
<span class="keyword">concept</span> Function = <span class="keyword">requires</span> (RT r, Args... a) {
  {F{}(a...)} -&gt; <span class="built-in">std::convertible_to</span>&lt;RT&gt;;
  <span class="built-in">std::copy_constructible</span>&lt;F&gt;;
};

<span class="keyword">template</span> &lt;<span class="keyword">typename</span> It, <span class="keyword">typename</span> T&gt;
<span class="keyword">concept</span> IteratorForFind = <span class="keyword">requires</span>(It i) {
  { *i } -&gt; <span class="built-in">std::convertible_to</span>&lt;T&gt;;
  { i++ } -&gt; <span class="built-in">std::convertible_to</span>&lt;It&gt;;
  <span class="built-in">std::equality_comparable_with</span>&lt;It, It&gt;;
};

<span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> It, <span class="keyword">typename</span> Comp&gt;
<span class="keyword">requires</span> IteratorForFind&lt;It, T&gt; && Function&lt;Comp, <span class="keyword">bool</span>, T&gt;
It my_find_if(It begin, It end, Comp c) {
  <span class="keyword">for</span>(; begin != end && !c(*begin); begin++);
  <span class="keyword">return</span> begin;
}

<span class="keyword">int</span> * find_int(<span class="keyword">int</span> n, <span class="keyword">int</span>* arr, <span class="keyword">int</span> key) {
    <span class="keyword">return</span> my_find_if&lt;<span class="keyword">int</span>&gt;(arr, arr + n, [key](<span class="keyword">int</span> i) { <span class="keyword">return</span> i == key;});
}
	    </pre>
            <div class="padded-text place-title">
	      This works, but got me wondering about the built-ins. Turns out the in <code class="built-in">iterator</code>, there are concepts for iterators already. (In hindsight, duh.) Here they use <code class="built-in">std::iterator_traits</code> to get at the value (duh, again).
            </div>
	    <pre>
<span class="keyword">#include</span> <span class="built-in">&lt;concepts&gt;</span>
<span class="keyword">#include</span> <span class="built-in">&lt;iterator&gt;</span>

<span class="keyword">template</span> &lt;<span class="built-in">std::forward_iterator</span> It, <span class="keyword">typename</span> Comp&gt;
<span class="keyword">requires</span> <span class="built-in">std::predicate</span>&lt;Comp, <span class="keyword">typename</span> <span class="built-in">std::iterator_traits</span>&lt;It&gt;::value_type&gt;
It my_find_if(It begin, It end, Comp c) {
  <span class="keyword">for</span> (; begin != end && !c(*begin); begin++);
  <span class="keyword">return</span> begin;
}

<span class="keyword">int</span>* find_int(<span class="keyword">int</span> n, <span class="keyword">int</span>* arr, <span class="keyword">int</span> key) {
  <span class="keyword">return</span> my_find_if(arr, arr + n, [key](<span class="keyword">int</span> i) { <span class="keyword">return</span> i == key; });
}
	    </pre>
            <div class="padded-text place-title">
	      Yeah, there's a built-in for predicats too. And this makes life really easy.
            </div>
          </div>

	  <div id="slide-21">
            <div class="big-title">References and TL;DR</div>
            <div class="padded-text">
	      <i>Yeah, this should've been everything, may be.</i>
            </div>
            <div class="big-title">TL;DR</div>
            <div class="padded-text place-title">
	      Instead of reading all of the stuff I wrote out, I think this summary would help:
	      <ul>
		<li>CPUs are not speeding up as much as they used to so hardware is specializing.</li>
		<li>One specialization is SIMD where, even commodity CPUs but especially in GPUs, one instruction acts on much data.</li>
		<li>Atomics provide ways to implement multi-threading.</li>
		<li>CPUs are confusing and complicated, and micro-architectural state is not easy.</li>
		<li>Benchmarking is difficult and specific datasets will make algorithms behave differently.</li>
		<li>Static guarantees and tooling is the best it's ever been and is only getting better.</li>
		<li>There's a wellspring of low-level systems languages. They're all modernizing C in many ways and agree on some interesting new trends, making code easier to understand.</li>
		<li>Compile-time programming is a great way to get static guarantees and code generation.</li>
		<li>Modules are the "right" way to do encapsulation.</li>
		<li>Resource allocation is initialization: that is, tie resources to object lifetimes.</li>
		<li>Error handling should fit in with other bits of code.</li>
		<li>Static and dynamic dispatch are well-understood, and you should know about that. This is applied in type erasure.</li>
		<li>C++20 concepts are really cool.</li>
	      </ul>
	      It's worth noting that this "slideshow" is a little bit of everything, best understood through larger complicated low-level (that is non-managed) languages. I've generally used C++ because it's the easiest for me to get my hands on examples, but Rust is just as good. Zig, Odin, C, and similar languages also could cover a lot of the earlier topics. I broadly call this systems programming since systems programmers seem to engineer large complex systems with the help of the latest programming tools and with great attention to how these abstract bits of code interact with the hardware. I'm not sure what the hard academic line is between systems programming, operating systems, distributed systems, programming language theory, and computer architecture -- I like to think that systems programming is a unification of all these topics.
            </div>
            <div class="big-title" id="works-cited">References</div>
            <div class="padded-text place-title">
	      You may not recall, but one of the titles mentioned CppCon. Here's why:
	      <table>
		<tr>
		  <th>Talk</th>
		  <th>Topics</th>
		</tr>
		<tr>
		  <td><a href="https://www.youtube.com/watch?v=6lurOCdaj0Y">Empirically Measuring, & Reducing, C++’s Accidental Complexity - Herb Sutter - CppCon 2020</a></td>
		  <td>This is about parameter passing (not something I talked about enough) which is a great example of declarative code.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/ImLFlLjSveM">How C++20 Changes the Way We Write Code - Timur Doumler - CppCon 2020</a></td>
		  <td>An overview of concepts, ranges, and coroutines as they will be in C++20.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/d_E-VLyUnzc">C++20 Ranges in Practice - Tristan Brindle - CppCon 2020</a></td>
		  <td>A detailed look at ranges. I love how this can interact with <code class="keyword">constexpr</code>.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/7oV7hiAsVTI">Structure and Interpretation of Computer Programs: SICP - Conor Hoekstra - CppCon 2020</a></td>
		  <td>Just another plug for both C++20 and one of my favorite books.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/Y1o4rc9P1FQ">How to Implement Your First Compiler Feature:The Story of Concepts in Clang - Saar Raz - CppCon 2019</a></td>
		  <td>A really fun look at the story of concepts in C++20 with a lot of good advice on collaboration and navigating a large codebase.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/3jCOwajNch0">Back to Basics: Lambdas from Scratch - Arthur O'Dwyer - CppCon 2019</a> and then <a href="https://youtu.be/tbUCHifyT24">Back to Basics: Type Erasure - Arthur O'Dwyer - CppCon 2019</a></td>
		  <td>A great coverage of lambdas and how they work followed by the talk that actually made me want to talk about type erasure.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/HG6c4Kwbv4I">CppCon 2019: Matt <span title="Sound familliar?">Godbolt</span> “Path Tracing Three Ways: A Study of C++ Style”</a></td>
		  <td>A really fun talk about some good C++ code, with a got bit on benchmarking.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/kIoZDUd5DKw">CppCon 2019: Matt Godbolt “Compiler Explorer: Behind The Scenes”</a></td>
		  <td>Explains some of compiler explorer, which is one of my favorite things.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/rHIkrotSwcc">CppCon 2019: Chandler Carruth “There Are No Zero-cost Abstractions”</a></td>
		  <td>I honestly don't fully remember what the talk was about. But it was good. I like the notion of "no zero-cost abstractions" given the explanations given here.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/v_yzLe-wnfk">CppCon 2019: Titus Winters “Maintainability and Refactoring Impact of Higher-Level Design Features”</a></td>
		  <td>Really similar to the above, but mentions how to refactor incrementally in really interesting ways.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/VN0VNoykxtk">CppCon 2019: Hyrum Wright Time Travel: Applying Gradual Typing to Time Types with Clang's LibTooling</a></td>
		  <td>Conversion of types and really neat arithmetic optimizations leading to a great library.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/ARYP83yNAWk">CppCon 2019: Herb Sutter “De-fragmenting C++: Making Exceptions and RTTI More Affordable and Usable”</a></td>
		  <td>This is a really neat summary on the entire error handling point I wanted to make.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/FJJTYQYB1JQ">CppCon 2019: Andrei Alexandrescu “Speed Is Found In The Minds of People"</a></td>
		  <td>A really good talk about benchmarking and optimization. This is the speaker who made me want to mention benchmarking.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/8khWb-Bhhvs">CppCon 2018: Jefferson Amstutz “Compute More in Less Time Using C++ Simd Wrapper Libraries”</a></td>
		  <td>A really good talk about SIMD, particularly about AVX and how to use it pratically.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/_f7O3IfIR2k">CppCon 2018: Chandler Carruth “Spectre: Secrets, Side-Channels, Sandboxes, and Security”</a></td>
		  <td>A great overview on the Spectre attack in the CPU.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/ncHmEUmJZf4">CppCon 2017: Matt Kulukundis “Designing a Fast, Efficient, Cache-friendly Hash Table, Step by Step”</a> and then <a href="https://youtu.be/JZE3_0qvrMg">CppCon 2019: Matt Kulukundis “Abseil's Open Source Hashtables: 2 Years In”</a></td>
		  <td>The talks that got me talking about hashmaps.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/kSWfushlvB8">CppCon 2017: Bob Steagall “How to Write a Custom Allocator”</a></td>
		  <td>A really nice overview of <code class="built-in">std::allocator</code> and the design of allocators. I wish I could discuss these -- allocators are essential in low-level programming.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/ZQFzMfHIxng">CppCon 2017: Fedor Pikus “C++ atomics, from basic to advanced. What do they really do?”</a></td>
		  <td><code class="built-in">std::atomic</code> and the talk that made me want to talk about those.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/YM8Xy6oKVQg">CppCon 2017: P. McKenney, M. Michael & M. Wong “Is Parallel Programming still hard? PART 1 of 2”</a> and then <a href="https://youtu.be/74QjNwYAJ7M">CppCon 2017: P. McKenney, M. Michael & M. Wong “Is Parallel Programming still hard? PART 2 of 2”</a></td>
		  <td>Very interesting survey on issues in parallel programming, particularly history and low-level details with caching. I should mention that I don't really like the speakers, but their content is awesome.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/4AfRAVcThyA">CppCon 2017: Herb Sutter “Meta: Thoughts on generative C++”</a></td>
		  <td>An ambitious proposal for generative C++ macros (they seem to be like better Rust procedural macros).</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/bSkpMdDe4g4">CppCon 2017: Matt Godbolt “What Has My Compiler Done for Me Lately? Unbolting the Compiler's Lid”</a></td>
		  <td>A tour through some really fun compiler optimizations powered by the compiler explorer.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/VvbTP_k_Df4">CppCon 2015:Marshall Clow “Type Traits - what are they and why should I use them?"</a></td>
		  <td>An overview of C++ types and the pre-concepts way to manage them. <span title="Substitution Failure Is Not An Error">SFINAE</span> go brr.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/WjTrfoiB0MQ">CppCon 2015: Andrei Alexandrescu “Declarative Control Flow"</a></td>
		  <td>Another chapter in the tale of exceptions: resolving resources through exceptions.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/JfmTagWcqoE">CppCon 2016: Herb Sutter “Leak-Freedom in C++... By Default.”</a></td>
		  <td>A memory management system for C++.</td>
		</tr>
	      </table>
	      Of course, cppcon is no longer the only set of good systems programming talks, and there are other interesting topics. Here are a few others from various other places:
	      <table>
		<tr>
		  <th>Talk</th>
		  <th>Topics</th>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/A3AdN7U24iU">Rust: A Language for the Next 40 Years - Carol Nichols</a></td>
		  <td>A good overview on how Rust was trending in mid 2019, outlining a lot of the philosophy and direction.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/NNwK5ZPAJCk">The Talk You've Been Await-ing for</a></td>
		  <td>An overview of Rust async/await that explains the architecture of the whole system in Rust, with wakers, polling, tasks, and all the malarchy.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/Z4oYSByyRak">Zig: A programming language designed for robustness, optimality, and clarity –  Andrew Kelley</a></td>
		  <td>An overview of Zig, by its creator.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/re96UgMk6GQ">Simon Peyton-Jones: Escape from the ivory tower: the Haskell journey</a></td>
		  <td>The tale of Haskell, as explained by one of its creators.</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/6COvD8oynmI">Adventure with Types in Haskell - Simon Peyton Jones (Lecture 1)</a> and the three subsequent lectures.</td>
		  <td>A tour through the implementation of Haskell's more complex type stuff. This is actually the first place that made me really think about dynamic dispatch as a small table of functions (I think that's in the second lecture somewhere).</td>
		</tr>
		<tr>
		  <td><a href="https://youtu.be/rCqFdYUnC24">Odin Programming Language: An Introduction - 2020-11-26</a></td>
		  <td>An overview of Odin, another "new C" programming language.</td>
		</tr>
	      </table>
	      If there's something incorrect in my writing, it's not due to the videos. It may be from my own experience or misremembering. Either way, blame me, and just watch the video.
            </div>
	  </div>
	</div>

        <div class="content-blog centered-div">
	  <div id="prev-slide" class="left-bit cv-link">Prev slide</div>
	  <div id="next-slide" class="right-bit cv-link">Next slide</div>
	  <div id="slide-ct" class="center-text centered-div"></div>
        </div>

        <div class="centered-div bottom-div">
            <a class="left-bit" href="mailto:hemang@ndhi.ninja">Email</a>
            <a class="right-bit" href="http://github.com/hemangandhi">GitHub</a>
            <div class="center-text"><a class="center-bit" href="http://www.linkedin.com/in/hemangandhi/">LinkedIn</a></div>
        </div>
    </body>
    <script>
      let ls = document.getElementById('slide-0');
      let slide_nav = document.getElementById('slide-nr');
      let i = 0;
      for(;(ls = document.getElementById('slide-' + i)) != null; i++) {
	  ls.style.display = "none";
	  let option = document.createElement('option');
	  option.value = "slide-" + i;
	  let title = ls.querySelector('.big-title');
	  if (title === null) {
	      title = ls.querySelector('div');
	  }
	  option.innerText = title.innerText;
	  slide_nav.appendChild(option);
      }

      function getSlideOfUrl() {
	  let id = window.location.hash;
	  if (!id.startsWith('#')) {
	      return 0;
	  } else if (id.startsWith('#slide-')) {
	      return parseInt(id.replace('#slide-', ''));
	  }
	  let node;
	  for(node = document.getElementById(id.substr(1)); node != document.body && !node.id.startsWith('slide-'); node = node.parentNode);
	  if (node == document.body) return 0;
	  let rv = parseInt(node.id.replace('slide-', ''));
	  if (rv > i - 1 || rv < 0) return 0;
	  return rv;
      }

      let curr_slide = getSlideOfUrl();
      function updateSlide() {
	  document.getElementById('slide-' + curr_slide).style.display = 'block';
	  document.getElementById('slide-ct').innerText = (curr_slide + 1) + '/' + i;
	  slide_nav.value = 'slide-' + curr_slide;
      }
      // Initialize the counter
      updateSlide();
      
      document.getElementById('next-slide').addEventListener('click', function (e) {
	  if(curr_slide == i - 1) return;
	  document.getElementById('slide-' + curr_slide).style.display = "none";
	  curr_slide++;
	  updateSlide();
      });
      document.getElementById('prev-slide').addEventListener('click', function (e) {
	  if(curr_slide == 0) return;
	  document.getElementById('slide-' + curr_slide).style.display = "none";
	  curr_slide--;
	  updateSlide();
      });

      slide_nav.addEventListener('change', function(e) {
	  document.getElementById('slide-' + curr_slide).style.display = "none";
	  curr_slide = parseInt(slide_nav.value.replace('slide-', ''));
	  updateSlide();
      });

      window.onhashchange = function(){
	  document.getElementById('slide-' + curr_slide).style.display = "none";
	  curr_slide = getSlideOfUrl();
	  updateSlide();
      };

      // Stuff for collapsible content
      const hide_synonyms = ['collapse', 'hide', 'skip'];
      const hide_antonyms = ['expand', 'show', 'read through'];
      function swapText(text, idx, is_collapse) {
	  if (is_collapse) {
	      return text.replace(hide_synonyms[idx], hide_antonyms[idx]);
	  }
          return text.replace(hide_antonyms[idx], hide_synonyms[idx]);
      }

      // OK, I hate me too
      function CollapseContent(c) {
	  let is_collapse = false;
	  function CollapseToggle(collapsible_kids, toggle) {
              toggle.classList.add('cv-link');
              let text = toggle.innerText;
              let i = 0;
              for(; i < hide_synonyms.length && !text.includes(hide_synonyms[i]); i++);
              if (i == hide_synonyms.length) {
		  toggle.innerText += " collapse";
		  i = 0;
	      }
	      this.idx = i;
	      this.t = toggle;
	      this.activate = function(toggles) {
		  toggle.addEventListener('click', function(e) {
	              is_collapse = !is_collapse;
	              toggles.forEach(function(t) {
			  t.t.innerText = swapText(t.t.innerText, t.idx, is_collapse);
		      });
	              collapsible_kids.forEach(function(k) { k.style.display = is_collapse ? "none" : "block"; });
		  });
	      }
	  }
	  
	  let collapsible_kids = c.querySelectorAll('.collapsible');
	  let toggles = Array.from(c.querySelectorAll('.collapse-handle'), function(t) {
	      return new CollapseToggle(collapsible_kids, t);
	  });
	  
	  this.activate = function() {
	      toggles.forEach(function(t) { t.activate(toggles); });
	  }
      }
      
      document.querySelectorAll('.collapsible-container').forEach(function(c) {
	  (new CollapseContent(c)).activate();
      });
    </script>
</html>
